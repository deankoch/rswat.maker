## code to prepare `statsgo_url` dataset
## template generated by running `usethis::use_data_raw('statsgo_url')`

## dependencies: `usethis` `rvest`, `dplyr` packages
## output: in your package data directory: /data/statsgo_url.rda


## constants

# an FPAC Box (USDA cloud platform) - view it in a web browser at: `file.path(base_url, dir_nm)`
base_url = 'https://nrcs.app.box.com'
dir_nm = 'v/soils/folder/18247487156'
page_count = 3


## helpers

# finds URLs for downloading STATSGO data by state
get_statsgo_url = function(base_url, dir_nm, page_count=3) {

  # written in 2020, still working in 2023!
  # as of 2023, all 51 states are available + 3 territories

  # helper function splits string `x` at pattern `p` and returns `i`th element(s)
  my_split = \(x, p, i=NULL) {

    # NULL i returns all
    v = unlist(strsplit(x, p))
    if( !is.null(i) ) v = v[i]
    return(v)
  }

  # base for all download links
  download_url = file.path(base_url, 'index.php?rm=box_download_shared_file&vanity_name=soils&file_id=')

  # loop over pages at NCRS website to copy relevant javascript as text
  nrcs_list = vector(mode='list', length=page_count)
  for(page_num in seq(page_count)) {

    directory_url = file.path(base_url,  paste0(dir_nm, '?page=', page_num))
    ncrs_nodes = rvest::session(directory_url) |> rvest::html_nodes(xpath='/html/body/script')
    nrcs_list[page_num] = ncrs_nodes[[length(ncrs_nodes)]] |> rvest::html_text()

  }

  # merge into a single blob of text
  nrcs_text = do.call(c, nrcs_list)

  # parse filenames and ID strings from file metadata chunks
  nrcs_meta = nrcs_text |> my_split('\"typedID\":\"') |> tail(-1) |> head(-1)
  nrcs_id = nrcs_meta |> sapply(\(txt) txt |> my_split('\"', 1))
  nrcs_file = nrcs_meta |> sapply(\(txt) txt |> my_split('\"name\":\"', 2) |> my_split('\"', 1))
  nrcs_df = dplyr::tibble( id = unname(nrcs_id) ) |>
    dplyr::mutate( file = unname(nrcs_file) ) |>
    dplyr::mutate( abb = sub('.+_([A-Z]{2})_.+.zip$', '\\1', file) ) |>
    dplyr::mutate( state = state.name[match(abb, state.abb)] ) |>
    dplyr::mutate( url = file.path(download_url, id)) |>
    dplyr::filter( !is.na(abb) ) |>
    dplyr::filter( abb != 'soils' )

  # filter some junk that got left behind
  nrcs_df |> dplyr::filter(is.na(state))
  return(nrcs_df)
}


## run

# call the helper to get STATSGO https download URLs
statsgo_url = base_url |> get_statsgo_url(dir_nm)

# save as package data
usethis::use_data(statsgo_url, overwrite=TRUE)


